{\rtf1\ansi\ansicpg1252\cocoartf1344\cocoasubrtf720
{\fonttbl\f0\froman\fcharset0 Palatino-Roman;}
{\colortbl;\red255\green255\blue255;}
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural

\f0\b\fs56 \cf0 Three approaches to automatic hyphenation\
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\fi360\sl288\slmult1\pardirnatural

\b0\fs32 \cf0 \
As computers came into use for typsetting and there where created computer typsetting systems to automate alot of the tasks of the typographer, there was a need for a way of hyphenating words automatically. When hyphenation is done by humans we usually intutivly know where a good hyphenation point in a word is because we know the word we are typing, we know the meaning and the origin of the word, and know the context in which the word is appearing. Eventhough the hyphenation might not be correct according the the official rules of the language the writer is writing in. Some languages have quite complicated rules for hyphenation (like Norwegian), that many people might not know about. But the most important goal of hyphenation is to not divide a word where it distracts and confuses the reader of the text. This is a process humans are quite good at. But for a computer to do this automatically, this is quite complicated, as it is hard for a computer to know the context of which the word is appearing, the meaning of the word, and the pronuncication of the word (which is especially important for american-english hyphenation). A lot of effort has gone into creating algorithms for achieving this. These algorithms can generally be devided into three approaches; rule based, dictionary based and pattern based algorithms. Often we can see algorithms uses a combination of these to achieve the best results. In the following chapters I will briefly describe these three approches.\
\
### Rule based hypenathion algorithms\
\
Rule based hyphenation algorithms take basis in the official hyphenation rules for a given language, and tries carefully to classify words into groups and apply the given rules. For instances Los Angeles Time developed a rule based hyphenation algorithm to be used in their typesetting system. The algorithm recognized words into vowel and conconant patterns, which then where divided into four groups and the given rules where then applied. They also used different special case rules and prefix and suffix rules. This apporach was reported to be "85--95 percent accurate". [Liang Thesis] \
\
Such an approach to hyphenation has multiple drawbacks. Firstly this is not a very general apporach to the problem. Different languages can have very different rules, and the algorithms often has to be completely written from the ground up to support a new language. This is also problematic for the american-english language where hypneation is based on pronouncication, which can change over time. Then it will be nececery to change the algorithm to encompass these new changes. It is not enough to change som parameters or run through the algorithm with some new input data. Another problem is that there is always exceptions to rules, and a list of exceptions can over time become unececarry huge. Thirdly, compund words, which we have a lot of in the norwegian language, can be hard for a computer algorithm to detect. How would a computer be able to understand that "fylkestrafikksikkerhetsutvalgssekritariatslederfunksjonene" is made up of a combination of multiple words and that it can hyphenate between these words? Not to mention that it has to recognize all the letter joints (TODO: ?fugebokstav) in the word to hyphenate correctly. [Liang, Gunnar]\
\
### Dictionary based hypenathion algorithms\
\
Dictionary based hypenation algorithms can be as simple as just a dictionary listing words and their hyphenation points. To hyphenate a word the algorithm only has to do a search in some form of data structure. The norwegian newspaper Aftenposten used this approach in the 90s, where IBM developed an algorithm that used a list of over 1,2 million hyphenated words. If the algorithm could not find the word it was trying to hyphenate in the list, it tried to hyphenate the word with some rule based logic. A full time hyphenator would the control the new word and it would be added to the dictionary. Aftenposten has since discarded this solution and now uses a proprietary system (TODO: Hvilket?). [Mail, Gunnar] To decrease the need to store such large lists of words (remember, it has to store all forms of a word, kake, kaker, kakene), other dictionary based approaches where developed. These other solutions where especilly nececerry in the time when proceccing speed and storage space where limited. One of these solutions is the Time magazine algorithm. It looked at all four letters surrounding each possible break point, and calculated the probability that an hyphen could occour at this point. And to save storage space, instead of having a table including all four letter combinations, 26^4 combinations, it used three tables of size 26^2 to store the three two-letter combination appearing in each for letter combination. For instance the word "ep-le" would be stored in three different tables as "ep", "pl" and "le". Probability is estimated as the product of these three values, and is compared against a threshold. [Liang] With todays computers the storage space and processing speed limitations would probably not be of big concern. \
\
A complete word list would be the perfect solution for the hyphenation problem. It would find 100 % of all hyphenation points with 0 % errors. But this is offcourse impossible. Hyphenation rules change, new words arises, and languages with a strong use of compound words, like Norwegian, can easily generate new words by combing older words. We see this everyday in the newspaper, like the word \'93skuldersurfing\'94 [http://www.aftenposten.no/digital/article7866596.ece, 19.01.2015, the day i wrote this]. So a dictionary based algorithm will never be able to hyphenate every word, it has to work in combination with some of the other apporaches or use manual labour when the word is not precent in the dictionary. \
\
### Pattern based hypenathion algorithms\
\
This approach will simply store string of letters (patterns) that will specify where to hyphenate. So when a pattern matches in a word, it will say where a hyphenation can be inserted in that word. For instance, we could have the pattern "sjon" that says that it is allowed to insert a hyphen before the word, like "-sjon". Then this pattern can be applied to words like "sta-sjon", "na-sjon" and "ak-sjon". Often the carachter "." is used to denote the start or end of a word. This apprpoach tend to be very compact, much more so than a dictionary based approach. But as always there are exceptions to these patterns as well, they will not always hyphenate correctly. But here we can also use patterns to compactly describe the exceptions, which will have precedence over the patterns describing the allowed hyphenation points. Some algorithms will have "exceptions to exceptions ..." in multiple levels, as the TeX-algorithm that I will describe in more detail later in this chapter.\
\
One problem with a solution like this is that it will have problem with homographs --- a word that shares the same written form as another word but has a different meaning [Wikipedia]. How would an algorithm know when we are using the word "bokskatter" to hyphenate it as "bok-skatter" or as "boks-katter" without looking at the entire context of the sentence?\
\
TODO: Sett inn bilde om boks-katter.\
}